{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4dd2dc2-30c8-421f-acc2-baaafe58a389",
   "metadata": {},
   "source": [
    "# Funathon 2023 - Sujet 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a28737-866c-4f4d-836d-9f825f426aad",
   "metadata": {},
   "source": [
    "Responsables :\n",
    "- Antoine Palazzolo, SSP Lab\n",
    "- Romain Avouac, DIIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78f28c-cd24-4564-a18f-b1a425e0b779",
   "metadata": {},
   "source": [
    "# Analyse textuelle des commentaires clients de services de commande de repas en ligne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bb9cf-32c4-4d10-8d22-f4977f139b2c",
   "metadata": {},
   "source": [
    "## Avant de commencer..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33b310-b100-4f10-9355-d1239fc5c162",
   "metadata": {},
   "source": [
    "Ce sujet, disponible uniquement en Python, porte sur deux thématiques principales :\n",
    "- Le web scraping\n",
    "- Le NLP\n",
    "\n",
    "Les deux parties sont indépendantes l'une de l'autre, il est donc possible de n'en faire qu'une des deux.\n",
    "\n",
    "Si jamais vous n'êtes pas familiers avec l'un de ces sujets (ou les deux), nous ne saurions que trop vous recommander de jeter un oeil aux ressources suivantes :\n",
    "- Débuter en web scraping : https://pythonds.linogaliana.fr/webscraping/\n",
    "- Web scraping et bonnes pratiques : https://github.com/InseeFrLab/formation-webscraping\n",
    "- Débuter en NLP : https://pythonds.linogaliana.fr/course/nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff71e0-37e9-4d64-86ee-d56aad2179f6",
   "metadata": {},
   "source": [
    "Exécutez la cellule ci-dessous pour installer les packages nécessaires au sujet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d56c1a6-fdb7-404a-81fd-503d5f4a0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22eda3-8c0f-4c06-b89b-ad9ed8fc3a6b",
   "metadata": {},
   "source": [
    "## Partie 1 : Scraping d'avis sur Trustpilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59941e3-e3e0-4aee-bc84-a0ea07318d5c",
   "metadata": {},
   "source": [
    "Pour pouvoir faire de l'analyse textuelle de commentaires clients, la première chose dont nous avons besoin c'est justement d'une base d'avis et de commentaires.\n",
    "Vous pourrez trouver de tels avis sur à peu près n'importe quel site de vente en ligne ou bien sur un certain nombre de comparateurs.\n",
    "En revanche, comment récupérer l'information depuis une page Internet pour nous constituer un jeu de données sur lequel travailler ?\n",
    "\n",
    "Eh bien c'est justement là qu'intervient le web scraping, qui permet de collecter automatiquement de l'information d'un site web, que ce soit du texte, des images, des tableaux, sans avoir à parcourir toutes les pages soi-même en faisant un copier-coller à la main du contenu.\n",
    "Le web scraping est donc un outil très puissant, mais à utiliser avec des pincettes.\n",
    "Cela doit plutôt être vu comme un dernier recours, lorsqu'il n'est pas possible d'accéder aux données plus facilement.\n",
    "\n",
    "En effet, de nombreuses contraintes juridiques encadrent par exemple le webscraping, il n'est pas possible de faire ce que l'on veut.\n",
    "Qui plus est, de plus en plus de sites apprennent à se défendre contre cette collecte automatique de leurs données, rendant la tâche plus difficile.\n",
    "Pour en savoir plus sur ces thématiques, n'hésitez pas à consulter cette formation : https://inseefrlab.github.io/formation-webscraping/.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7881c38-f813-4edb-81af-60867441cb1a",
   "metadata": {},
   "source": [
    "Les données mises à disposition pour ce sujet ont été extraites du site https://fr.trustpilot.com/.\n",
    "Votre première tâche va être de créer votre propre scraper pour pouvoir recréer une base similaire.\n",
    "\n",
    "Afin de ne pas surcharger le traffic du site, nous n'allons pas vous demander d'en scraper l'intégralité.\n",
    "Vous allez donc vous limiter à une entreprise de votre choix parmi celles de la catégorie _takeaway_ : https://fr.trustpilot.com/categories/takeaway.\n",
    "Cliquez sur le lien et promenez-vous sur le site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f4a85-4502-4dab-8cc6-2972a3e3dff2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Bien préparer son scraping : découvrir le site ciblé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5665ee-b086-48b4-a1da-19c263062ced",
   "metadata": {},
   "source": [
    "La première chose à faire pour tout bon adepte de scraping, c'est apprendre à connaître la page web cible :\n",
    "- A quoi ressemble l'url du site ? Y a-t-il un radical commun lorsque l'on passe d'une page à une autre ? Par exemple ici lorsque l'on change d'entreprise comparée ou que l'on va chercher les avis les plus reculés ?\n",
    "- Quelles sont les informations disponibles sur la page ? Y a-t-il besoin de cliquer sur un bouton pour les faire apparaître ?\n",
    "- Les différentes pages que je souhaite scraper ont-elles bien des formats similaires ? La construction des pages change-t-elle d'une entreprise comparée à une autre ?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b655c8-4d2e-4bdd-8585-a9ff36922dc9",
   "metadata": {},
   "source": [
    "Il faut ensuite aller un peu plus loin dans l'analyse et regarder la structure HTML de la page ciblée.\n",
    "Si vous n'êtes pas familiers avec cette partie, n'hésitez pas à consulter les ressources précédemment citées.\n",
    "\n",
    "Tout d'abord, choisissez l'entreprise dont vous allez extraire les commentaires et cliquez sur sa page Trustpilot.\n",
    "A présent, après un clic droit sur un élément de la page, il suffit de cliquer sur \"Inspecter l'élément\" pour naviguer dans l'architecture de la page et analyser le positionnement de l'élément sélectionné.\n",
    "Cliquez sur divers éléments de la page pour vous familiariser avec sa structure.\n",
    "- Comment sont rangés les commentaires ? Comprenez-vous bien l'arborescence de la page ?\n",
    "- Regardez les balises autour de chaque note, y a-t-il un pattern ou un élément commun qui permet de les identifier et les distinguer des autres ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a6eb8-7356-434c-ac49-23c598f97b73",
   "metadata": {},
   "source": [
    "### 2. Premiers pas : récupérer l'information du nombre de pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db647d1c-6a1b-4c35-ab23-76ee6c837808",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03da2e6b-b6cf-46f5-80e3-a635f7d43bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "radical_trustpilot = '' # TODO\n",
    "company = '' # TODO\n",
    "\n",
    "url_company = radical_trustpilot + company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15cfc33-ce00-4508-b4c6-23478a4c5725",
   "metadata": {},
   "source": [
    "Maintenant que vous avez votre premier lien à scraper, il va falloir envoyer une __requête__ au site pour demander à en récupérer le contenu, sous le format HTML.\n",
    "C'est sur le contenu retourné que nous travaillerons ensuite.\n",
    "\n",
    "En Python, un package permet facilement de faire ces requêtes, il s'agit de _requests_, et plus précisément de la fonction ```requests.get()```, qui prend en argument l'url ciblé.\n",
    "En plus du lien à requêter, la fonction peut prendre d'autres arguments, appelés __headers__, comme _User_Agent_ ou _From_ qui permettent de s'identifier lors de la requête envoyée au site.\n",
    "\n",
    "Pourquoi s'identifier me demanderez-vous ? Eh bien tout d'abord parce qu'il s'agit là d'une bonne pratique de scraping.\n",
    "Les sites reçoivent parfois énormément de requêtes sur leurs pages, par exemple à cause de scrapers trop gourmands, et cela peut leur créer des problèmes.\n",
    "Ils peuvent donc être amenés à par exemple bloquer les adresses IP des utilisateurs jugés abusifs.\n",
    "S'identifier clairement dans ses requêtes, en explicitant le but de la collecte, permet de faire preuve de transparence.\n",
    "Même si en pratique cela n'arrive que très peu, cela laisse alors la possibilité au propriétaire du site de contacter le scraper afin d'avoir plus d'informations sur le but de la collecte, et possiblement offrir l'accès aux données sans scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09af359-c980-4b23-a51e-24c8b8b3eaa6",
   "metadata": {},
   "source": [
    "Une autre bonne pratique pour ne pas être trop agressif vis-à-vis du site scrapé est d'étaler ses requêtes dans le temps, par exemple en forçant votre code à prendre une pause d'au moins 3 secondes entre chaque requête effectuée si vous visitez plusieurs pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e42e5c-6fbd-469d-9524-120e143df29a",
   "metadata": {},
   "source": [
    "Ici, complétez les headers ci-dessous avec vos informations pour faire preuve de transparence auprès de Trustpilot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7625b4e-3d17-4298-af07-1293dd8658a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': '', # Nom, entité, but de la collecte, informations pertinentes\n",
    "    'From': '' # Coordonnées à laisser au propriétaire du site en cas de besoin\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9cab2-4d9a-4594-b2be-a6cd554c5409",
   "metadata": {},
   "source": [
    "Nous réutiliserons ces headers dans toutes les requêtes du sujet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f91af-4057-48ad-9692-375c46ae2302",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Créer sa première requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5778b51a-1052-4611-b375-1d208bdc8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708dde0f-286f-474d-9b37-58570f38ac17",
   "metadata": {},
   "source": [
    "Utilisez la fonction ```requests.get()``` et vos headers pour requêter votre site, puis utilisez la méthode ```.text``` pour récupérer le contenu HTML de la page désirée sous forme de texte.\n",
    "\n",
    "Vous pouvez aussi déjà prendre le réflexe d'ajouter un ```time.sleep(3)``` à l'issue de chaque requête effectuée pour ne pas surcharger le site lorsque nous aurons davantage de requêts à faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d937339-d024-4b88-8280-f000bfa4e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body>We have received an unusually large amount of requests from your IP so you have been rate limited</body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_text = '' # TODO\n",
    "\n",
    "print(request_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09374891-4340-4d36-b5da-d8b3681a69b0",
   "metadata": {},
   "source": [
    "Si vous avez bien fait les choses, vous devriez maintenant avoir quelque chose d'assez illisible, c'est normal.\n",
    "Il va maintenant falloir faire appel à un autre package pour __parser__ cette chaîne de caractères en une arborescence plus exploitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1e5d4-157b-49dd-8d18-725b8d9b2ab6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Parsing d'un document HTML : BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c9a1f-9159-4e2d-9d17-6339c84f9301",
   "metadata": {},
   "source": [
    "La fonction ```BeautifulSoup()```, du package du même nom, est ce qui va nous permettre de faire ce parsing.\n",
    "Rien de tel que l'essayer sur notre texte pour voir quel est son effet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a68869c4-353b-4260-9ec5-df3f68baf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a2f35f-97aa-4193-bda4-80878e14c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body>We have received an unusually large amount of requests from your IP so you have been rate limited</body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = '' # TODO\n",
    "\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f7ba7-0611-4f16-a9ad-e9e9b91eddc2",
   "metadata": {},
   "source": [
    "Normalement ça a déjà une meilleure tête !\n",
    "On dira que le contenu HTML est désormais sous la forme d'une _soupe_.\n",
    "L'idée maintenant va être de naviguer parmi l'arborescence des balises dans cette _soupe_ pour aller chercher l'information que l'on souhaite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d7e70-8f4e-4e0d-b7fb-e5c478da1420",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Chercher un élément dans l'arborescence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a3979-1674-4749-988c-32456bc2e933",
   "metadata": {},
   "source": [
    "Deux méthodes sont particulièrement utiles lorsque l'on travaille avec BeautifulSoup :\n",
    "\n",
    "- ```soup.find(type_de_balise, {'class': classe_de_la_balise)```, pour trouver le premier le premier élément correspondant à la recherche effectuée\n",
    "    + La méthode ```.text``` permet ensuite d'en extraire le contenu textuel affiché sur le site\n",
    "- ```soup.find_all(type_de_balise, {'class': classe_de_la_balise)```, pour renvoyer la liste de tous les éléments correspondant à la recherche effectuée\n",
    "\n",
    "Les types de balise sont souvent assez standards : ```div```, ```a```, ```span```.\n",
    "Quant aux noms de classes, ils ne sont pas toujours très explicites, mais que cela ne vous décourage pas !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed5398-c1ad-434d-87cc-cf59d248203d",
   "metadata": {},
   "source": [
    "Pour commencer, entraînez-vous à manipuler ces deux fonctions en récupérant des informations diverses sur le site. Vous pouvez également imbriquer plusieurs de ces fonctions les unes après les autres, l'output d'une recherche pouvant être une plus petite _soupe_ pour donnée en input d'une nouvelle recherche.\n",
    "\n",
    "Quand vous êtes prêts, utilisez les méthodes ci-dessus pour associer à la variable ```nb_pages``` le nombre de pages d'avis pour l'entreprise considérée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ebc6c-b8d5-42a1-b4a8-4617ae863231",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pages = 0  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb2b14-b3d2-48d6-9b12-255959b5d5f3",
   "metadata": {},
   "source": [
    "Indice : Le nombre de pages est accessible au bas de la page. En revanche, la balise contenant l'information et son nom de classe ne sont peut-être pas uniques..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c84cd-c0fb-4958-ab63-bd4f68540e85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Mise sous fonction (et corrigé)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c8006-a15d-4d45-8d48-7c16cce4a4ac",
   "metadata": {},
   "source": [
    "Maintenant que vous avez compris le principe, il est temps de regrouper tout ce qui a été fait en une fonction ```get_nb_pages_review()``` prenant en entrée un cible et renvoyant le nombre de pages d'avis.\n",
    "Attention cette fois à rajouter une condition d'exception si jamais aucune balise du type désirée n'est trouvée..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052a5ea-379a-45f9-bd7d-d1fb07e2dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_pages_reviews(url_company):\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83c6f8-8886-4b6b-a911-d9d365450109",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_test_1 = radical_trustpilot + \"deligreens.com\"\n",
    "get_nb_pages_reviews(url_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eab3de-3965-4f4d-be8d-2e24a9d1cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_test_2 = radical_trustpilot + \"entreprise_mystere.com\"  # Entreprise qui n'existe pas\n",
    "get_nb_pages_reviews(url_test_2)  # Doit pouvoir s'exécuter sans erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde2543-0c39-426b-9513-403f4917a5b1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Dérouler pour révéler le corrigé</summary>\n",
    "<br>\n",
    "\n",
    "```{python}\n",
    "def get_nb_pages_reviews(url_company):\n",
    "\n",
    "    time.sleep(3)\n",
    "    request_text = requests.get(url_company, headers=headers).text\n",
    "    soup = BeautifulSoup(request_text, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        boutons_pages = soup.find(\n",
    "            'div', {'class':'styles_pagination__6VmQv'}\n",
    "        ).find_all(\n",
    "            'span', {'class':'typography_heading-xxs__QKBS8 typography_appearance-inherit__D7XqR typography_disableResponsiveSizing__OuNP7'}\n",
    "        )\n",
    "        last_page = int(boutons_pages[-2].text)  # Dernier bouton = \"Page Suivante\"\n",
    "        return last_page\n",
    "\n",
    "    except:\n",
    "        return 0\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510209e-e411-4d9b-a8dd-00d707d2501d",
   "metadata": {},
   "source": [
    "### 3. Mise en pratique : récupérer les avis d'une entreprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878dc47-9f82-44ae-8bbd-8e578c3a53cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Récupérer les informations au sein d'une review donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa22f3b4-3364-4d3a-bbe5-e00e1705a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24236cd6-1690-4ac3-804b-be366356e7a6",
   "metadata": {},
   "source": [
    "Imaginez que vous avez sous la main le code HTML (sous forme de _soupe_) relatif à une seule review sur votre page (vous pouvez voir en inspectant la page que chaque review est contenue dans une balise ```div``` distincte, les unes après les autres).\n",
    "\n",
    "Nous allons maintenant tâcher de récupérer les informations relatives à une review à l'aide de la méthode ```.find()```. Complétez les fonctions ci-dessous, sans oublier de rattraper les exceptions s'il y a un problème quelconque avec votre review d'entrée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13935e2f-de5b-4b3d-b4a5-911ed6a033dc",
   "metadata": {},
   "source": [
    "Attention, les fonctions ci-dessous demandent parfois de récupérer autre chose que du texte, il faudra donc réfléchir à des alternatives à la méthode ```.text```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365bbf2-ebf5-48c3-8a80-6b8de4289801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_note_review(review):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        review: contenu HTML sous la forme d'une soupe BeautifulSoup (str)\n",
    "\n",
    "    Outputs:\n",
    "        note: Note de l'avis (entier entre 1 et 5)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe104a-f940-4062-9642-2e87b647d083",
   "metadata": {},
   "source": [
    "Indices :\n",
    "- Pour récupérer un texte dans une balise _img_, un argument supplémentaire peut être passé à la fonction ```.find()```,  il s'agit de ```alt=True```\n",
    "- Penser à convertir le texte récupéré en une note sous la forme d'entier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e46f88-1547-40ac-bb3a-9dc8448a89f9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Dérouler pour révéler le corrigé</summary>\n",
    "<br>\n",
    "\n",
    "```{python}\n",
    "def get_note_review(review):\n",
    "    \n",
    "    try:\n",
    "        texte_note = review.find(\n",
    "            'div', {'class':'star-rating_starRating__4rrcf star-rating_medium__iN6Ty'}\n",
    "        ).find('img', alt=True)['alt']\n",
    "        note = int(texte_note[5])  # texte_note = \"Noté x étoiles sur 5\"\n",
    "        return note\n",
    "\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79070f1-3743-43b6-9ae7-57b46e751ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_review(review):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        review: contenu HTML sous la forme d'une soupe BeautifulSoup (str)\n",
    "\n",
    "    Outputs:\n",
    "        date: Date et heure de l'avis (datetime)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab9ded-5f6d-4ff3-bb6a-20a280fde382",
   "metadata": {},
   "source": [
    "Indice : La fonction ```datetime.strptime()``` permet de convertir la chaîne de caractères récupérée en un format date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc153086-85f2-4b81-8a9a-aafe45e48ae5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Dérouler pour révéler le corrigé</summary>\n",
    "<br>\n",
    "\n",
    "```{python}\n",
    "def get_time_review(review):\n",
    "    \n",
    "    try:\n",
    "        str_date = review.find(\n",
    "            'div', {'class':'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_datesWrapper__RCEKH'}\n",
    "        ).find('time')['datetime']\n",
    "        date = datetime.strptime(str_date, \"%Y-%m-%dT%H:%M:%S.%fZ\")  # str_date = 'YYYY-MM-DDThh:mm:ss.000Z'\n",
    "        return date\n",
    "\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f337a-c380-419d-bcaf-8d2ee73df4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_review(review):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        review: contenu HTML sous la forme d'une soupe BeautifulSoup (str)\n",
    "\n",
    "    Outputs:\n",
    "        title: Titre de la review (str)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6a4b2-f2b7-4714-b7cd-5d40a1a20f22",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Dérouler pour révéler le corrigé</summary>\n",
    "<br>\n",
    "\n",
    "```{python}\n",
    "def get_title_review(review):\n",
    "    \n",
    "    try:\n",
    "        title = review.find(\n",
    "            'h2', {'class':'typography_heading-s__f7029 typography_appearance-default__AAY17'}\n",
    "        ).text\n",
    "        return title\n",
    "\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb5f30-90df-4ca9-a041-8f06b35b08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_review(review):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        review: contenu HTML sous la forme d'une soupe BeautifulSoup (str)\n",
    "\n",
    "    Outputs:\n",
    "        comment: Commentaire associé à la review (str)\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92162bd3-ea50-49a1-b230-a92448b82fac",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Dérouler pour révéler le corrigé</summary>\n",
    "<br>\n",
    "\n",
    "```{python}\n",
    "def get_comment_review(review):\n",
    "    \n",
    "    try:\n",
    "        text = review.find(\n",
    "            'p', {'class':'typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn'}\n",
    "        ).text # Les balises <br> sont supprimées, on va donc forcer des espaces après les points\n",
    "        text = re.sub(' +', ' ', text.replace('.', '. '))\n",
    "        return text\n",
    "\n",
    "    except:\n",
    "        return \"Not found\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b140978-d047-46f1-909b-7cb980fc3159",
   "metadata": {},
   "source": [
    "#### Scraper toutes les reviews d'une entreprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627fd57-aaab-49e6-9659-25245e97e491",
   "metadata": {},
   "source": [
    "Nous sommes désormais capables de récupérer toutes les informations contenues dans une review donnée.\n",
    "Reste maintenant à itérer sur l'ensemble des reviews d'une page, puis sur l'ensemble des pages (limité à 5 pages pour ne pas surcharger le site cible).\n",
    "\n",
    "Complétez la fonction ci-dessous pour récupérer l'ensemble des informations extraites des reviews en un dataframe aisément manipulable.\n",
    "\n",
    "Attention : bien penser à ajouter des pauses entre chaque requête d'au moins 3 secondes à l'aide de la commande ```time.sleep(3)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ece84e-ee8c-4585-9cb0-1b5eb61328cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2da98101-089b-4ca2-98ea-72df48c5c9a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 8 (2906935917.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_reviews = pd.DataFrame({\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 8\n"
     ]
    }
   ],
   "source": [
    "def scraping_one_company(url_company, limit_pages=True):\n",
    "\n",
    "    nb_pages = get_nb_pages_reviews(url_company)\n",
    "    if limit_pages and nb_pages > 5:\n",
    "        nb_pages = 5\n",
    "    notes, times, titles, comments = [], [], [], []\n",
    "\n",
    "    for page in tqdm(range(1, nb_pages+1)):\n",
    "\n",
    "        # TODO\n",
    "\n",
    "    df_reviews = pd.DataFrame({\n",
    "        'note': notes,\n",
    "        'date': times,\n",
    "        'title': titles,\n",
    "        'comment': comments\n",
    "    })\n",
    "\n",
    "    return df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5318d4ef-2b49-45de-ab34-77f89179c965",
   "metadata": {},
   "source": [
    "Indices :\n",
    "- Quel va être l'url à requêter pour chaque page ?\n",
    "- Souvenez-vous de la fonction ```.find_all()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef015f9-4c82-47dc-8db6-c56602f7cc92",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Dérouler pour révéler le corrigé</summary>\n",
    "<br>\n",
    "\n",
    "```{python}\n",
    "def scraping_one_company(url_company, limit_pages=True):\n",
    "\n",
    "    nb_pages = get_nb_pages_reviews(url_company)\n",
    "    if limit_pages and nb_pages > 5:\n",
    "        nb_pages = 5\n",
    "    notes, times, titles, comments = [], [], [], []\n",
    "\n",
    "    for page in tqdm(range(1, nb_pages+1)):\n",
    "\n",
    "        time.sleep(3)\n",
    "        url_page = url_company + '?page=' + str(page)\n",
    "        \n",
    "        try:\n",
    "            request_text = requests.get(url_page, headers=headers).text\n",
    "            soup = BeautifulSoup(request_text, 'html.parser')\n",
    "            reviews = soup.find_all(\n",
    "                'div', {'class':'styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ'}\n",
    "            )\n",
    "        except:\n",
    "            reviews = []\n",
    "\n",
    "        notes.extend(list(map(get_note_review, reviews)))\n",
    "        times.extend(list(map(get_time_review, reviews)))\n",
    "        titles.extend(list(map(get_title_review, reviews)))\n",
    "        comments.extend(list(map(get_comment_review, reviews)))\n",
    "\n",
    "    df_reviews = pd.DataFrame({\n",
    "        'note': notes,\n",
    "        'date': times,\n",
    "        'title': titles,\n",
    "        'comment': comments\n",
    "    })\n",
    "\n",
    "    return df_reviews\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d680a1-2fab-4a6c-8ab8-79a2fbe6ce27",
   "metadata": {},
   "source": [
    "### 4. Collecte et vérification des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6370dc-bc7f-4442-aedc-3770d16b9bc9",
   "metadata": {},
   "source": [
    "Maintenant nos fonctions codées, il ne reste plus qu'à mettre en pratique et récupérer nos avis !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a08f1-6ed1-4a59-9503-708f0c963856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = scraping_one_company(url_company, limit_pages=True)\n",
    "\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae4da5-030b-431f-8cbf-0e51e1f2d3a4",
   "metadata": {},
   "source": [
    "Lorsque l'on scrape des données sur Internet, la qualité attendue n'est pas toujours au rendez-vous.\n",
    "Il convient donc de bien vérifier ce qui est obtenu en sortie pour ne pas avoir de mauvaises surprises.\n",
    "Prenez un moment pour analyser vos données de sortie :\n",
    "\n",
    "- Le format des colonnes est-il bon ? Les textes ont-ils tous bien une apparence lisible ?\n",
    "- Y a-t-il des NaNs dans certaines colonnes ? Autrement dit des informations possiblement manquantes pour certaines reviews sur le site ?\n",
    "- Avez-vous bien le nombre de lignes attendu en sortie ?\n",
    "\n",
    "Pourquoi ne pas faire quelques visualisations avec matplotlib pour regarder à quoi ressemblent les distributions de nos variables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5a58d5c-2961-435e-b65f-17dc0421fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e138ea-cf9e-4f5e-88e5-73e266244de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amusez-vous ici avec df_reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbe95b-6f1b-4925-b0bf-d6fe0ff0c0f9",
   "metadata": {},
   "source": [
    "La partie scraping est à présent terminée.\n",
    "La table que vous trouverez pour la seconde partie du sujet a été obtenue par scraping en itérant ce que vous avez recodé sur une liste donnée d'entreprises.\n",
    "\n",
    "Si vous souhaitez en savoir plus sur le monde du web scraping ou si vous voulez réitérer l'expérience sur d'autres sites, n'hésitez pas à consulter les ressources mentionnées au début du sujet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9f5f2-5692-42af-86ca-75646213fa03",
   "metadata": {},
   "source": [
    "## Partie 2 : Analyse textuelle et NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f0ebb-7f31-4b61-9711-18f55699e813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
